{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2023-10-11 10:15:51--  https://www.lawrence.edu/fast/greggj/CMSC490/shakespeare.zip\n",
      "Resolving www.lawrence.edu (www.lawrence.edu)... 143.44.124.14\n",
      "Connecting to www.lawrence.edu (www.lawrence.edu)|143.44.124.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www7.lawrence.edu/fast/greggj/CMSC490/shakespeare.zip [following]\n",
      "--2023-10-11 10:15:51--  https://www7.lawrence.edu/fast/greggj/CMSC490/shakespeare.zip\n",
      "Resolving www7.lawrence.edu (www7.lawrence.edu)... 143.44.124.14\n",
      "Connecting to www7.lawrence.edu (www7.lawrence.edu)|143.44.124.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www2.lawrence.edu/fast/greggj/CMSC490/shakespeare.zip [following]\n",
      "--2023-10-11 10:15:51--  https://www2.lawrence.edu/fast/greggj/CMSC490/shakespeare.zip\n",
      "Resolving www2.lawrence.edu (www2.lawrence.edu)... 143.44.124.14\n",
      "Connecting to www2.lawrence.edu (www2.lawrence.edu)|143.44.124.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://www2.lawrence.edu/fast/GREGGJ/CMSC490/shakespeare.zip [following]\n",
      "--2023-10-11 10:15:51--  http://www2.lawrence.edu/fast/GREGGJ/CMSC490/shakespeare.zip\n",
      "Connecting to www2.lawrence.edu (www2.lawrence.edu)|143.44.124.14|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2139870 (2.0M) [application/zip]\n",
      "Saving to: ‘shakespeare.zip’\n",
      "\n",
      "shakespeare.zip     100%[===================>]   2.04M  8.09MB/s    in 0.3s    \n",
      "\n",
      "2023-10-11 10:15:52 (8.09 MB/s) - ‘shakespeare.zip’ saved [2139870/2139870]\n",
      "\n",
      "Archive:  shakespeare.zip\n",
      "  inflating: shakespeare.txt         \n",
      "  inflating: __MACOSX/._shakespeare.txt  \n"
     ]
    }
   ],
   "source": [
    "!wget http://www.lawrence.edu/fast/greggj/CMSC490/shakespeare.zip\n",
    "!unzip shakespeare.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that reads single word from file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWord(file):\n",
    "    char = file.read(1)\n",
    "    if not char:\n",
    "        return ''\n",
    "    char = char.lower()\n",
    "\n",
    "    while char < 'a' or char > 'z':\n",
    "        char = file.read(1)        \n",
    "        if not char: \n",
    "            return ''\n",
    "        char = char.lower()\n",
    "\n",
    "    str = ''\n",
    "    while char >= 'a' and char <= 'z':\n",
    "        str = str + char\n",
    "        char = file.read(1)        \n",
    "        if not char: \n",
    "            return str\n",
    "        char = char.lower()\n",
    "    \n",
    "    if char == '’':\n",
    "        str = ''\n",
    "        char = file.read(1)\n",
    "        if not char: \n",
    "            return str\n",
    "        char = char.lower()\n",
    "        while char >= 'a' and char <= 'z':\n",
    "            char = file.read(1)        \n",
    "            if not char: \n",
    "                return str\n",
    "            char = char.lower()\n",
    "        return getWord(file)\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "words = np.zeros(100000, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('shakespeare.txt', 'r')\n",
    "\n",
    "for n in range(0,len(words)):\n",
    "    words[n] = getWord(file)\n",
    " \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSequence(ch):\n",
    "    if ch == ' ':\n",
    "        position = 26\n",
    "    else:\n",
    "        position = ord(ch) - ord('a')\n",
    "    encodedNum = np.zeros(27)\n",
    "    encodedNum[position] = 1\n",
    "    return encodedNum\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "substrings = np.zeros((100000,10,27))\n",
    "targets = np.zeros((100000,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSubstrings(encoded):\n",
    "    substring = encoded[:]\n",
    "    numBlank =10 - len(encoded)\n",
    "    for i in range(numBlank):\n",
    "        blank = np.zeros(27)\n",
    "        blank[26] = 1\n",
    "        substring.append(blank)\n",
    "    return substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0 #to keep track of how many things i've added to the substrings, target array\n",
    "for i in range(len(words)):\n",
    "    \n",
    "    if len(words[i]) < 4 or len(words[i]) > 9:\n",
    "        continue\n",
    "\n",
    "    if k >= 100000:\n",
    "        break\n",
    "    chars = list(words[i]) # \"h\", \"o\", \"u\", \"s\", \"e\"\n",
    "    encoded = [makeSequence(chars[0]),makeSequence(chars[1]),makeSequence(chars[2])]\n",
    "    substrings[k] = genSubstrings(encoded)\n",
    "\n",
    "    targets[k] = makeSequence(chars[3])\n",
    "    k+=1\n",
    "\n",
    "    for n in range(3,len(chars)):\n",
    "        encoded.append(makeSequence(chars[n]))\n",
    "        substrings[k] = genSubstrings(encoded)\n",
    "        if n+1 == len(chars): #when the substring is equal to the original string\n",
    "            targets[k] = makeSequence(' ')\n",
    "        else:\n",
    "            targets[k] = makeSequence(chars[n+1])\n",
    "        k+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = substrings[:60000]\n",
    "x_test = substrings[60000:80000]\n",
    "x_val = substrings[80000:]\n",
    "\n",
    "Y_train = targets[:60000]\n",
    "y_test = targets[60000:80000]\n",
    "y_val = targets[80000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "60000\n",
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((substrings, targets))\n",
    "# train_size = int(0.6 * len(dataset))\n",
    "# val_size = int(0.2 * len(dataset))\n",
    "# test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# train_dataset = dataset.take(train_size)\n",
    "# remaining_dataset = dataset.skip(train_size)\n",
    "# val_dataset = remaining_dataset.take(val_size)\n",
    "# test_dataset = remaining_dataset.skip(val_size)\n",
    "\n",
    "# print(len(dataset))\n",
    "# print(len(train_dataset))\n",
    "# print(len(val_dataset))\n",
    "# print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.LSTM(16,input_shape=(10,27),return_sequences=False),\n",
    "    layers.Dense(27, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 2.4062 - accuracy: 0.3484 - val_loss: 2.4091 - val_accuracy: 0.3460\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 2.2287 - accuracy: 0.3850 - val_loss: 2.3232 - val_accuracy: 0.3738\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 2.0980 - accuracy: 0.4188 - val_loss: 2.2163 - val_accuracy: 0.3857\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.9784 - accuracy: 0.4561 - val_loss: 2.1162 - val_accuracy: 0.4188\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.8815 - accuracy: 0.4823 - val_loss: 2.0582 - val_accuracy: 0.4321\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.8041 - accuracy: 0.5035 - val_loss: 2.0085 - val_accuracy: 0.4465\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7473 - accuracy: 0.5186 - val_loss: 1.9801 - val_accuracy: 0.4575\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.7019 - accuracy: 0.5305 - val_loss: 1.9586 - val_accuracy: 0.4708\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6628 - accuracy: 0.5397 - val_loss: 1.9449 - val_accuracy: 0.4626\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6313 - accuracy: 0.5505 - val_loss: 1.9272 - val_accuracy: 0.4791\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.6044 - accuracy: 0.5577 - val_loss: 1.9116 - val_accuracy: 0.4832\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.5803 - accuracy: 0.5634 - val_loss: 1.9101 - val_accuracy: 0.4879\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.5596 - accuracy: 0.5691 - val_loss: 1.8866 - val_accuracy: 0.4944\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.5406 - accuracy: 0.5723 - val_loss: 1.8887 - val_accuracy: 0.5019\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.5233 - accuracy: 0.5775 - val_loss: 1.8848 - val_accuracy: 0.5045\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.5066 - accuracy: 0.5808 - val_loss: 1.8814 - val_accuracy: 0.5006\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.4931 - accuracy: 0.5831 - val_loss: 1.8729 - val_accuracy: 0.5058\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.4780 - accuracy: 0.5874 - val_loss: 1.8679 - val_accuracy: 0.5045\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.4648 - accuracy: 0.5915 - val_loss: 1.8548 - val_accuracy: 0.5055\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.4525 - accuracy: 0.5960 - val_loss: 1.8509 - val_accuracy: 0.5113\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=20,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
